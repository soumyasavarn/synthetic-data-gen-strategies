{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2230588,"sourceType":"datasetVersion","datasetId":1339985}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport glob\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image, make_grid\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n\n# 1. Config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nROOT      = '/kaggle/input/comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela'\nFACES_DIR = os.path.join(ROOT, 'faces')\nCOMICS_DIR= os.path.join(ROOT, 'comics')\nBATCH_SIZE= 128\nNUM_WORKERS= 0\nIMAGE_SIZE = 256\n\n# 2. Dataset\nclass Paired10Dataset(Dataset):\n    def __init__(self, real_dir, comic_dir, transform):\n        self.real_paths  = sorted(glob.glob(os.path.join(real_dir, '*.jpg')))[:8000]\n        self.comic_paths = sorted(glob.glob(os.path.join(comic_dir, '*.jpg')))[:8000]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.real_paths)\n\n    def __getitem__(self, idx):\n        real  = Image.open(self.real_paths[idx]).convert('RGB')\n        comic = Image.open(self.comic_paths[idx]).convert('RGB')\n        return self.transform(real), self.transform(comic)\n\ntransform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3),\n])\n\n# <<< FIXED HERE >>>\ndataset = Paired10Dataset(\n    real_dir  = FACES_DIR,\n    comic_dir = COMICS_DIR,\n    transform = transform\n)\nloader = DataLoader(\n    dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS\n)\nprint(f\"Loaded {len(dataset)} samples, {len(loader)} batches.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:32:22.594711Z","iopub.execute_input":"2025-04-19T16:32:22.595312Z","iopub.status.idle":"2025-04-19T16:32:22.648512Z","shell.execute_reply.started":"2025-04-19T16:32:22.595289Z","shell.execute_reply":"2025-04-19T16:32:22.647750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef conv_block(in_c, out_c, norm=True):\n    layers = [nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False)]\n    if norm: layers.append(nn.BatchNorm2d(out_c))\n    layers.append(nn.LeakyReLU(0.2, inplace=True))\n    return nn.Sequential(*layers)\n\ndef deconv_block(in_c, out_c, dropout=False):\n    layers = [\n        nn.ConvTranspose2d(in_c, out_c, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(out_c),\n        nn.ReLU(inplace=True)\n    ]\n    if dropout: layers.append(nn.Dropout(0.5))\n    return nn.Sequential(*layers)\n\nclass UNetGenerator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Downsampling (8 blocks)\n        self.d1 = conv_block(3, 64, norm=False)\n        self.d2 = conv_block(64, 128)\n        self.d3 = conv_block(128, 256)\n        self.d4 = conv_block(256, 512)\n        self.d5 = conv_block(512, 512)\n        self.d6 = conv_block(512, 512)\n        self.d7 = conv_block(512, 512)\n        self.d8 = conv_block(512, 512)\n        # Upsampling (8 blocks)\n        self.u1 = deconv_block(512, 512, dropout=True)\n        self.u2 = deconv_block(1024, 512, dropout=True)\n        self.u3 = deconv_block(1024, 512, dropout=True)\n        self.u4 = deconv_block(1024, 512)\n        self.u5 = deconv_block(1024, 256)\n        self.u6 = deconv_block(512, 128)\n        self.u7 = deconv_block(256, 64)\n        self.final = nn.Sequential(\n            nn.ConvTranspose2d(128, 3, 4, 2, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        # Encoder\n        d1 = self.d1(x); d2 = self.d2(d1)\n        d3 = self.d3(d2); d4 = self.d4(d3)\n        d5 = self.d5(d4); d6 = self.d6(d5)\n        d7 = self.d7(d6); d8 = self.d8(d7)\n        # Decoder with skip connections\n        u1 = self.u1(d8);         u2 = self.u2(torch.cat([u1, d7],1))\n        u3 = self.u3(torch.cat([u2, d6],1))\n        u4 = self.u4(torch.cat([u3, d5],1))\n        u5 = self.u5(torch.cat([u4, d4],1))\n        u6 = self.u6(torch.cat([u5, d3],1))\n        u7 = self.u7(torch.cat([u6, d2],1))\n        return self.final(torch.cat([u7, d1],1))\n\n\nclass PatchDiscriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            conv_block(6, 64, norm=False),\n            conv_block(64,128),\n            conv_block(128,256),\n            conv_block(256,512),\n            nn.Conv2d(512,1,4,1,1)  # output 30×30 patch\n        )\n    def forward(self, x, y):\n        return self.model(torch.cat([x,y], dim=1))\n\n\n\n\n\n\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nG = UNetGenerator().to(device)  \nD = PatchDiscriminator().to(device)\nopt_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\nopt_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\nadv_loss = nn.BCEWithLogitsLoss()  \nl1_loss  = nn.L1Loss()\nLAMBDA_L1 = 100\nEPOCHS = 120\nSAVE_EVERY = 40\n\nhistory = {'G': [], 'D': []}\nfor epoch in range(1, EPOCHS+1):\n    g_running, d_running = 0.0, 0.0\n\n    for real_A, real_B in loader:\n        real_A, real_B = real_A.to(device), real_B.to(device)\n\n        # Dynamically get PatchGAN output for real pair\n        pred_real = D(real_A, real_B)  \n\n        # Create matching real/fake targets\n        valid = torch.ones_like(pred_real)   # real=1 :contentReference[oaicite:6]{index=6}\n        fake  = torch.zeros_like(pred_real)  # fake=0 :contentReference[oaicite:7]{index=7}\n\n        # Generator step\n        opt_G.zero_grad()\n        fake_B    = G(real_A)\n        pred_fake = D(real_A, fake_B)\n        loss_G    = adv_loss(pred_fake, valid) + LAMBDA_L1 * l1_loss(fake_B, real_B)\n        loss_G.backward()\n        opt_G.step()\n\n        # Discriminator step\n        opt_D.zero_grad()\n        loss_D_real = adv_loss(pred_real, valid)\n        loss_D_fake = adv_loss(pred_fake.detach(), fake)\n        loss_D      = 0.5 * (loss_D_real + loss_D_fake)\n        loss_D.backward()\n        opt_D.step()\n\n        g_running += loss_G.item()\n        d_running += loss_D.item()\n\n    # Log epoch losses\n    history['G'].append(g_running / len(loader))\n    history['D'].append(d_running / len(loader))\n    print(f\"Epoch {epoch} | G: {history['G'][-1]:.4f} | D: {history['D'][-1]:.4f}\")\n\n    # Checkpoint\n    if epoch % SAVE_EVERY == 0:\n        torch.save(G.state_dict(), f\"generator_{epoch}.pth\")\n        torch.save(D.state_dict(), f\"discriminator_{epoch}.pth\")\n\n\n\nplt.figure(figsize=(8,4))\nplt.plot(history['G'], label='Generator')  \nplt.plot(history['D'], label='Discriminator')\nplt.xlabel('Epoch'); plt.ylabel('Loss')\nplt.title('Training Loss'); plt.legend()\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:32:35.350738Z","iopub.execute_input":"2025-04-19T16:32:35.351469Z","iopub.status.idle":"2025-04-19T16:48:48.673104Z","shell.execute_reply.started":"2025-04-19T16:32:35.351444Z","shell.execute_reply":"2025-04-19T16:48:48.672108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\n\n# Set the generator to evaluation mode\nG.eval()\n\n# Retrieve a batch of real images and their corresponding comic images\nreal_A, real_B = next(iter(loader))\nreal_A, real_B = real_A.to(device), real_B.to(device)\n\n# Generate fake comic images without computing gradients\nwith torch.no_grad():\n    fake_B = G(real_A)\n\n# Create a grid of images: real input, generated output, and ground truth\ngrid = make_grid(torch.cat([real_A, fake_B, real_B], 0), nrow=2, normalize=True)\n\n# Move the grid to CPU and convert to NumPy for plotting\ngrid_np = grid.cpu().permute(1, 2, 0).numpy()\n\n# Plot the images\nplt.figure(figsize=(6, 6))\nplt.imshow(grid_np)\nplt.axis('off')\nplt.title('Real → Generated → Comic GT')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:13:34.924910Z","iopub.execute_input":"2025-04-19T13:13:34.925556Z","iopub.status.idle":"2025-04-19T13:13:35.239768Z","shell.execute_reply.started":"2025-04-19T13:13:34.925533Z","shell.execute_reply":"2025-04-19T13:13:35.239143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}